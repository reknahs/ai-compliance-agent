# AI Compliance & Security Agent ğŸ›¡ï¸

A multi-step, memory-aware RAG agent designed to answer questions about AI compliance and security frameworks (NIST AI RMF, EU AI Act, ISO 42001, etc.).

Built with **LangGraph**, **LangChain**, and **Mem0** to provide context-aware, verifiable, and safe responses.

## ğŸš€ Key Features

- **ğŸ§  Hybrid Memory System**: Integrates **Mem0** (for semantic user history) and a custom **ChromaDB** solution to recall past interactions and user preferences.
- **ğŸ”„ Multi-Step Reasoning**: Uses a graph-based workflow (Intent Analysis â†’ Retrieval â†’ Synthesis â†’ Validation) to ensure high-quality answers.
- **âœ… Self-Correction**: Automatically validates responses against retrieved evidence and loops back to refine answers if claims are unsupported.
- **ğŸ‘¤ User Profiling**: extract and learns facts about the user (e.g., "I work in FinTech", "Our servers are in Germany") to tailor compliance advice.
- **ğŸ•µï¸ Fact Extraction**: Passively extracts and learns new information from conversations to build a dynamic knowledge base.
- **âœ‹ Human-in-the-Loop**: Optional approval step ensures sensitive compliance advice is verified before delivery.

## ğŸ› ï¸ Technology Stack

- **Framework**: [LangChain](https://www.langchain.com/) & [LangGraph](https://langchain-ai.github.io/langgraph/)
- **Memory**: [Mem0](https://mem0.ai/) & ChromaDB
- **LLMs**: Gemini (via Google GenAI) or Llama 3 (via Ollama)
- **Evaluation**: [DeepEval](https://github.com/confident-ai/deepeval)
- **Vector Store**: ChromaDB

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ src/
â”‚   â””â”€â”€ compliance_agent/
â”‚       â”œâ”€â”€ main.py              # Entry point & Agent Graph definition
â”‚       â”œâ”€â”€ memory/              # Memory implementations (Mem0 & Custom)
â”‚       â”œâ”€â”€ steps/               # Individual graph nodes (Analyze, Retrieve, Synthesize, etc.)
â”‚       â””â”€â”€ schemas/             # Pydantic models for structured output
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ memory_store/          # Local ChromaDB for custom memory
â”‚   â””â”€â”€ evaluation_results/    # Logs of performance tests
â”œâ”€â”€ evals/                       # DeepEval test suite
â””â”€â”€ requirements.txt             # Project dependencies
```

## âš¡ Setup & Installation

### 1. Prerequisites
- Python 3.10+
- [Ollama](https://ollama.com/) (if using local LLMs)
- Google AI Studio API Key (if using Gemini)

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Environment Config
Create a `.env` file in the root directory:
```bash
GOOGLE_API_KEY=your_google_api_key
MEMORY_API_KEY=your_mem0_api_key  # Optional if using custom memory
```

### 4. Ingest Documents (Required)
Before running the agent, you must ingest the compliance documents (PDFs) into the vector store:

1. Place your PDF documents (e.g., EU AI Act, NIST AI RMF) in `data/sources/`.
2. Run the ingestion script:
   ```bash
   python -m src.compliance_agent.ingestion
   ```
   This will chunk the documents and create a local ChromaDB vector store in `data/vector_store/`.

## ğŸƒ Usage

### Run the Agent
Start the interactive CLI:
```bash
python -m src.compliance_agent.main
```

### Options
- Use local custom memory (ChromaDB) instead of Mem0 Cloud:
  ```bash
  python -m src.compliance_agent.main --custom-memory
  ```
- Pass a query directly:
  ```bash
  python -m src.compliance_agent.main "What are the key requirements of the EU AI Act?"
  ```

## ğŸ§ª Evaluation

Run the comprehensive test suite to measure RAG performance, Memory recall, and Fact Extraction accuracy:

```bash
python -m evals.run_evaluation
```

Key metrics tracked:
- **RAG**: Answer Relevancy, Faithfulness, Hallucination
- **Memory**: Recall accuracy of user details
- **Extraction**: Precision of fact extraction from conversation

---
*Built for the GenAI era of Compliance.* 
